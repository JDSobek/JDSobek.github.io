---
title: 'Extending Imagenet models to 3-Dimensional Data'
date: 2021-02-15
permalink: /posts/2021/02/Imagenet-in-3D/
tags:
  - Deep Learning
  - Computer Vision
  - Pytorch
---

The Problem
======
One of the major obstacles faced in medical imaging is the sparsity of annotated, or labeled, data.  This can make it difficult to balance the need for deep learning models to train long enough to be useful while avoiding overfitting to the training data.  One of the easiest ways to address this is to give your model a headstart using transfer learning, which means initializing the model with parameters that were useful for another task before starting the training process.

Limitations of Transfer Learning
------
For many machine learning tasks, transfer learning handily solves several problems accompanying training on small datasets, but it imposes some strict, but straightforward, limitations on your model.  The first of these is that, in order to load transfer learned parameters into your model, the pretrained parameters must be compatible with the layer they are being loaded into.  For most practical purposes this means a significant portion of your model must have the same architecture as the model you are taking your parameters from.  The second is that your data must be fairly similar to the data the parameters were trained on, at least in regards to its overall dimensionality and the number of input channels.

ImageNet
------
[ImageNet](http://www.image-net.org/), a huge dataset of labeled "natural images" (e.g. standard color photographs), provides one of the computer vision community's favorite classification tasks to test the mettle of novel computer vision models.  Thanks to its easy availability and large size using ImageNet allows you to avoid the many issues that come with small datasets, and most widely used sets of pretrained parameters for computer vision models have been trained using ImageNet.

However, ImageNet can be difficult to apply to medical imaging.  This isn't because ImageNet is distinctly lacking any medical imaging, the parameters that result are often surprisingly generalizable, but because every image is strictly a 2-dimensional, 3-channel (RGB) image while medical imaging (at least CT data, which has been the focus of my work) is 3-dimensional, single channel data.



One Solution (Using Resnet)
======
my code
